{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtree import decisionTree\n",
    "from bagger import bagger\n",
    "from boost import boost\n",
    "from WeightedBagger import WeightedBagger\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 303 \ttrain: 100\t test: 203\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/heart.csv')\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "y = data[\"target\"]\n",
    "y = np.array(y)\n",
    "x = data.drop(columns = ['target'])\n",
    "x = np.array(x)\n",
    "\n",
    "trainSize = 100\n",
    "print(\"total samples: %d \\ttrain: %d\\t test: %d\" % (y.__len__(),trainSize,y.__len__()-trainSize))\n",
    "xtrain, xtest = x[:trainSize],x[trainSize:]\n",
    "ytrain, ytest = y[:trainSize],y[trainSize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score for my binary classifications models written using numpy with same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple decision tree: \t0.6897\n",
      "Majority trees voting: \t0.8374\n",
      "weighted Bagger: \t0.7882\n",
      "boosted forrest: \t0.7833\n"
     ]
    }
   ],
   "source": [
    "tree = decisionTree()\n",
    "tree.fit(xtrain,ytrain)\n",
    "print(\"Simple decision tree: \\t%.4f\"%accuracy_score(ytest,tree.predict(xtest)))\n",
    "\n",
    "bagg = bagger()\n",
    "bagg.fit(xtrain,ytrain)\n",
    "print(\"Majority trees voting: \\t%.4f\"%accuracy_score(ytest,bagg.predict(xtest)))\n",
    "\n",
    "wb = WeightedBagger()\n",
    "wb.fit(xtrain,ytrain)\n",
    "print(\"weighted Bagger: \\t%.4f\"%accuracy_score(ytest,wb.predict(xtest)))\n",
    "\n",
    "\n",
    "bost = boost()\n",
    "bost.fit(xtrain,ytrain)\n",
    "print(\"boosted forrest: \\t%.4f\"%accuracy_score(ytest,bost.predict(xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few hours of coding I realised that I've got the idea of boosting wrong.\n",
    "Gonna make it work after I'll write weighted decision tree.\n",
    "I'm trying to write a boost using insights from MIT lecture about artificial intelligence.\n",
    "\n",
    "https://youtu.be/UHBmv7qCey4\n",
    "\n",
    "Accuracy score for sklearn model and xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost XGBClassifier: \t0.4335\n",
      "sklearn gradientboost: \t0.4335\n"
     ]
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "xgboost.fit(xtrain,ytrain)\n",
    "print(\"xgboost XGBClassifier: \\t%.4f\"%accuracy_score(ytest,xgboost.predict(xtest)))\n",
    "\n",
    "sklearn = GradientBoostingClassifier()\n",
    "sklearn.fit(xtrain,ytrain)\n",
    "print(\"sklearn gradientboost: \\t%.4f\"%accuracy_score(ytest,sklearn.predict(xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
